{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_of_training_records = 20000 # -1 for all recods in the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "dataframe = pd.read_csv('/data/CognitiveBanking/data/train_indessa.csv')\n",
    "dataframe = dataframe.head(no_of_training_records)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from os.path import expanduser\n",
    "modelDir = expanduser(\"~\")+'/model'\n",
    "tbDir = expanduser(\"~\")+'/tb'\n",
    "\n",
    "if os.path.exists(modelDir):\n",
    "    shutil.rmtree(modelDir) \n",
    "    os.makedirs(modelDir)\n",
    "else:\n",
    "    os.makedirs(modelDir)\n",
    "print(os.listdir(modelDir))\n",
    "modelPath = modelDir+'/model.ckpt'\n",
    "\n",
    "\n",
    "if os.path.exists(tbDir):\n",
    "    shutil.rmtree(tbDir) \n",
    "    os.makedirs(tbDir)\n",
    "else:\n",
    "    os.makedirs(tbDir)\n",
    "tb_logs_path = tbDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "traindf, validatedf = train_test_split(dataframe, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe.loc[:, (\"y1\")] = dataframe.loc[:, (\"loan_status\")]\n",
    "dataframe.loc[:, (\"y2\")] = dataframe[\"y1\"] == 0           # y2 is the negation of y1\n",
    "dataframe.loc[:, (\"y2\")] = dataframe[\"y2\"].astype(int)    # Turn TRUE/FALSE values into 1/0\n",
    "\n",
    "\n",
    "traindf.loc[:, (\"y1\")] = traindf.loc[:, (\"loan_status\")]\n",
    "traindf.loc[:, (\"y2\")] = traindf[\"y1\"] == 0           # y2 is the negation of y1\n",
    "traindf.loc[:, (\"y2\")] = traindf[\"y2\"].astype(int)    # Turn TRUE/FALSE values into 1/0\n",
    "\n",
    "\n",
    "validatedf.loc[:, (\"y1\")] = validatedf.loc[:, (\"loan_status\")]\n",
    "validatedf.loc[:, (\"y2\")] = validatedf[\"y1\"] == 0           # y2 is the negation of y1\n",
    "validatedf.loc[:, (\"y2\")] = validatedf[\"y2\"].astype(int)    # Turn TRUE/FALSE values into 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def min_max_scale_normalization(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    return pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = dataframe.loc[:, ['loan_amnt',\n",
    "                           'funded_amnt',\n",
    "                           'funded_amnt_inv', \n",
    "                           'int_rate',\n",
    "                           'annual_inc', \n",
    "                           'dti',\n",
    "                           'open_acc', \n",
    "                           'revol_bal',\n",
    "                           'revol_util', \n",
    "                           'total_acc',\n",
    "                           'total_rec_int', \n",
    "                           'tot_cur_bal',\n",
    "                           'total_rev_hi_lim',\n",
    "                           'y1',\n",
    "                           'y2']].dropna()\n",
    "\n",
    "\n",
    "#df = min_max_scale_normalization(df)\n",
    "\n",
    "inputX = df.loc[:, ['loan_amnt',\n",
    "                           'funded_amnt',\n",
    "                           'funded_amnt_inv', \n",
    "                           'int_rate',\n",
    "                           'annual_inc', \n",
    "                           'dti',\n",
    "                           'open_acc', \n",
    "                           'revol_bal',\n",
    "                           'revol_util', \n",
    "                           'total_acc',\n",
    "                           'total_rec_int', \n",
    "                           'tot_cur_bal',\n",
    "                           'total_rev_hi_lim'\n",
    "                           ]].as_matrix()\n",
    "\n",
    "inputY = df.loc[:, [\"y1\"]].as_matrix()\n",
    "\n",
    "\n",
    "print(inputX.shape)\n",
    "print(inputY.shape)\n",
    "print('\\n')\n",
    "\n",
    "traindf = traindf.loc[:, ['loan_amnt',\n",
    "                           'funded_amnt',\n",
    "                           'funded_amnt_inv', \n",
    "                           'int_rate',\n",
    "                           'annual_inc', \n",
    "                           'dti',\n",
    "                           'open_acc', \n",
    "                           'revol_bal',\n",
    "                           'revol_util', \n",
    "                           'total_acc',\n",
    "                           'total_rec_int', \n",
    "                           'tot_cur_bal',\n",
    "                           'total_rev_hi_lim',\n",
    "                           'y1',\n",
    "                           'y2']].dropna()\n",
    "\n",
    "\n",
    "#traindf = min_max_scale_normalization(traindf)\n",
    "\n",
    "inputXtrain = traindf.loc[:, ['loan_amnt',\n",
    "                           'funded_amnt',\n",
    "                           'funded_amnt_inv', \n",
    "                           'int_rate',\n",
    "                           'annual_inc', \n",
    "                           'dti',\n",
    "                           'open_acc', \n",
    "                           'revol_bal',\n",
    "                           'revol_util', \n",
    "                           'total_acc',\n",
    "                           'total_rec_int', \n",
    "                           'tot_cur_bal',\n",
    "                           'total_rev_hi_lim'\n",
    "                           ]].as_matrix()\n",
    "\n",
    "inputYtrain = traindf.loc[:, [\"y1\"]].as_matrix()\n",
    "print(inputXtrain.shape)\n",
    "print(inputYtrain.shape)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "validatedf = validatedf.loc[:, ['loan_amnt',\n",
    "                           'funded_amnt',\n",
    "                           'funded_amnt_inv', \n",
    "                           'int_rate',\n",
    "                           'annual_inc', \n",
    "                           'dti',\n",
    "                           'open_acc', \n",
    "                           'revol_bal',\n",
    "                           'revol_util', \n",
    "                           'total_acc',\n",
    "                           'total_rec_int', \n",
    "                           'tot_cur_bal',\n",
    "                           'total_rev_hi_lim',\n",
    "                           'y1',\n",
    "                           'y2']].dropna()\n",
    "\n",
    "#validatedf = min_max_scale_normalization(validatedf)\n",
    "\n",
    "\n",
    "inputXvalidate = validatedf.loc[:, ['loan_amnt',\n",
    "                           'funded_amnt',\n",
    "                           'funded_amnt_inv', \n",
    "                           'int_rate',\n",
    "                           'annual_inc', \n",
    "                           'dti',\n",
    "                           'open_acc', \n",
    "                           'revol_bal',\n",
    "                           'revol_util', \n",
    "                           'total_acc',\n",
    "                           'total_rec_int', \n",
    "                           'tot_cur_bal',\n",
    "                           'total_rev_hi_lim'\n",
    "                           ]].as_matrix()\n",
    "\n",
    "inputYvalidate = validatedf.loc[:, [\"y1\"]].as_matrix()\n",
    "\n",
    "print(inputXvalidate.shape)\n",
    "print(inputYvalidate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(inputXtrain, np.ravel(inputYtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(inputXvalidate)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(inputXvalidate, inputYvalidate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "timeStart = datetime.datetime.now()\n",
    "kfold = model_selection.KFold(n_splits=100, random_state=7)\n",
    "modelCV = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(modelCV, inputXtrain, np.ravel(inputYtrain), cv=kfold, scoring=scoring)\n",
    "timeEnd = datetime.datetime.now()\n",
    "executionTime = timeEnd - timeStart\n",
    "print(\"Executon Time \", executionTime  )\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(inputYvalidate, logreg.predict(inputXvalidate))\n",
    "fpr, tpr, thresholds = roc_curve(inputYvalidate, logreg.predict_proba(inputXvalidate)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
